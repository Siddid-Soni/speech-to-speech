{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddid/miniconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Iterator\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.google import Gemini\n",
    "from kokoro import KPipeline\n",
    "from IPython.display import display, Audio\n",
    "import soundfile as sf\n",
    "import os\n",
    "import threading\n",
    "import queue\n",
    "import re\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddid/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/home/siddid/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "pipeline = KPipeline(lang_code='a')  # 'a' for American English\n",
    "voice = 'af_heart'  # Choose your preferred voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "        model=Gemini(id=\"gemini-2.0-flash\", api_key=\"\"),\n",
    "        description=\"You are a voice-assistant model\",\n",
    "        instructions=\"include proper punctuations for good pronunciation and do not use any markdown or symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"audio_chunks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RealTimeAudioStreamer:\n",
    "    def __init__(self, tts_pipeline, voice=\"af_heart\", speed=1.0):\n",
    "        self.pipeline = tts_pipeline\n",
    "        self.voice = voice\n",
    "        self.speed = speed\n",
    "        self.text_queue = queue.Queue()\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.text_processing_thread = None\n",
    "        self.audio_playback_thread = None\n",
    "        self.stop_event = threading.Event()\n",
    "        self.full_text = \"\"\n",
    "        self.chunk_index = 0\n",
    "        self.sentence_buffer = \"\"\n",
    "        \n",
    "    def process_text_to_audio(self):\n",
    "        \"\"\"Thread function to convert text chunks to audio\"\"\"\n",
    "        while not self.stop_event.is_set() or not self.text_queue.empty():\n",
    "            try:\n",
    "                # Get text from queue with 0.1s timeout\n",
    "                text_chunk = self.text_queue.get(timeout=0.2)\n",
    "                \n",
    "                # Add to sentence buffer\n",
    "                self.sentence_buffer += text_chunk\n",
    "                \n",
    "                # Check if we have complete sentences to process\n",
    "                sentences = self._split_into_sentences(self.sentence_buffer)\n",
    "                \n",
    "                if sentences:\n",
    "                    # Process complete sentences\n",
    "                    keep_buffer = sentences.pop()  # Keep incomplete sentence in buffer\n",
    "                    self.sentence_buffer = keep_buffer\n",
    "                    \n",
    "                    for sentence in sentences:\n",
    "                        if sentence.strip():\n",
    "                            # Generate audio for this sentence\n",
    "                            for _, _, audio in self.pipeline(sentence, voice=self.voice, speed=self.speed):\n",
    "                                # Put audio in queue for playback thread\n",
    "                                self.audio_queue.put(audio)\n",
    "                                \n",
    "                                # Save the audio chunk\n",
    "                                audio_path = f\"audio_chunks/chunk_{self.chunk_index}.wav\"\n",
    "                                sf.write(audio_path, audio, 24000)\n",
    "                                self.chunk_index += 1\n",
    "                \n",
    "                self.text_queue.task_done()\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(f\"Error in audio processing: {e}\")\n",
    "    \n",
    "    def play_audio(self, autoplay=True):\n",
    "        \"\"\"Thread function to play audio chunks as they become available\"\"\"\n",
    "        while not self.stop_event.is_set() or not self.audio_queue.empty():\n",
    "            try:\n",
    "                # Get audio from queue with 0.1s timeout\n",
    "                audio = self.audio_queue.get(timeout=0.1)\n",
    "                \n",
    "                # Play the audio\n",
    "                display(Audio(data=audio, rate=24000, autoplay=autoplay))\n",
    "                \n",
    "                self.audio_queue.task_done()\n",
    "                \n",
    "                # Small delay to avoid overloading the display\n",
    "                time.sleep(0.05)\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(f\"Error in audio playback: {e}\")\n",
    "    \n",
    "    def _split_into_sentences(self, text):\n",
    "        \"\"\"Split text into sentences, keeping the last incomplete sentence in buffer\"\"\"\n",
    "        # Basic sentence splitting on punctuation\n",
    "        sentence_endings = re.finditer(r'([.!?])\\s+', text)\n",
    "        \n",
    "        # Find positions of all sentence endings\n",
    "        end_positions = [match.end() for match in sentence_endings]\n",
    "        \n",
    "        if not end_positions:\n",
    "            # No complete sentence found, return original text as buffer\n",
    "            return [text]\n",
    "        \n",
    "        # Extract complete sentences\n",
    "        sentences = []\n",
    "        start_pos = 0\n",
    "        \n",
    "        for end_pos in end_positions:\n",
    "            sentences.append(text[start_pos:end_pos])\n",
    "            start_pos = end_pos\n",
    "        \n",
    "        # Add remaining text (incomplete sentence) as the last item\n",
    "        sentences.append(text[start_pos:])\n",
    "        \n",
    "        return sentences\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the processing and playback threads\"\"\"\n",
    "        self.stop_event.clear()\n",
    "        \n",
    "        # Start text processing thread\n",
    "        self.text_processing_thread = threading.Thread(\n",
    "            target=self.process_text_to_audio, \n",
    "            daemon=True\n",
    "        )\n",
    "        self.text_processing_thread.start()\n",
    "        \n",
    "        # Start audio playback thread\n",
    "        self.audio_playback_thread = threading.Thread(\n",
    "            target=self.play_audio, \n",
    "            daemon=True\n",
    "        )\n",
    "        self.audio_playback_thread.start()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the processing and playback threads\"\"\"\n",
    "        self.stop_event.set()\n",
    "        \n",
    "        # Process any remaining text in the buffer\n",
    "        if self.sentence_buffer.strip():\n",
    "            for _, _, audio in self.pipeline(self.sentence_buffer, voice=self.voice, speed=self.speed):\n",
    "                self.audio_queue.put(audio)\n",
    "                audio_path = f\"audio_chunks/chunk_{self.chunk_index}.wav\"\n",
    "                sf.write(audio_path, audio, 24000)\n",
    "                self.chunk_index += 1\n",
    "        \n",
    "        # Wait for threads to finish\n",
    "        if self.text_processing_thread:\n",
    "            self.text_processing_thread.join(timeout=5)\n",
    "        if self.audio_playback_thread:\n",
    "            self.audio_playback_thread.join(timeout=5)\n",
    "        \n",
    "        # Generate complete audio file\n",
    "        self._save_full_audio()\n",
    "    \n",
    "    def add_text(self, text):\n",
    "        \"\"\"Add text to the processing queue\"\"\"\n",
    "        self.text_queue.put(text)\n",
    "        self.full_text += text\n",
    "    \n",
    "    def _save_full_audio(self):\n",
    "        \"\"\"Generate and save audio for the full text\"\"\"\n",
    "        print(\"Generating full audio from complete response...\")\n",
    "        full_audio = []\n",
    "        for _, _, audio in pipeline(self.full_text, voice=self.voice, speed=self.speed, split_pattern=r'\\n+'):\n",
    "            full_audio.append(audio)\n",
    "        \n",
    "        # Concatenate and save full audio\n",
    "        if full_audio:\n",
    "            full_audio_array = np.concatenate(full_audio)\n",
    "            sf.write(\"audio_chunks/full_response.wav\", full_audio_array, 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stream_to_speech_realtime(prompt: str, play_audio: bool = True):\n",
    "    \"\"\"Process streamed LLM response with real-time audio conversion and playback\"\"\"\n",
    "    # Get streaming response\n",
    "    response_stream: Iterator[RunResponse] = agent.run(prompt, stream=True)\n",
    "    \n",
    "    # Create and start audio streamer\n",
    "    audio_streamer = RealTimeAudioStreamer(pipeline, voice=voice)\n",
    "    audio_streamer.start()\n",
    "    \n",
    "    try:\n",
    "        # Process each chunk as it arrives\n",
    "        for chunk in response_stream:\n",
    "            if chunk.content:\n",
    "                # Add text to the processing queue\n",
    "                audio_streamer.add_text(chunk.content)\n",
    "        \n",
    "        # Stop streamer when all text is processed\n",
    "        audio_streamer.stop()\n",
    "        \n",
    "        return audio_streamer.full_text\n",
    "    except Exception as e:\n",
    "        audio_streamer.stop()\n",
    "        print(f\"Error during streaming: {e}\")\n",
    "        return audio_streamer.full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating full audio from complete response...\n",
      "Complete response: David Goggins is an American ultramarathon runner, ultra-distance cyclist, triathlete, motivational speaker, and author. He is a retired United States Navy SEAL and former world record holder for the most pull-ups done in 24 hours.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"who is david goggins\"\n",
    "full_response = process_stream_to_speech_realtime(prompt)\n",
    "print(\"Complete response:\", full_response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
